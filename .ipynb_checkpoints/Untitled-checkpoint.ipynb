{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup \n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "from urllib.parse import urlparse\n",
    "import re\n",
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "\n",
    "def findExternalLinks(siteUrl):\n",
    "\n",
    "        req = requests.get(siteUrl)\n",
    "        soup = BeautifulSoup(req.content, 'html.parser')\n",
    "        \n",
    "        links = [x.get('href') for x in soup.findAll('a')]\n",
    "        \n",
    "        for a in links:\n",
    "            a = str(a)\n",
    "            if(a.startswith('http')):\n",
    "                 print(a)\n",
    "#                 pass\n",
    "            elif(a.startswith('/')): \n",
    "                domain = urlparse(siteUrl).netloc\n",
    "                print(domain + a)\n",
    "                try:\n",
    "                    domain = \"https://\" + domain\n",
    "                    code = urlopen(domain + a).code\n",
    "                    print(domain + a + \"WWWWWWWWWWWWWWWWWWWW\")\n",
    "                except:\n",
    "#                     pass\n",
    "                    print(a + \"Cant OPEN!\")\n",
    "            else:\n",
    "                print(a + \"i dont start good\")\n",
    "#                 pass\n",
    "                \n",
    "findExternalLinks('http://www.bouwmaterialen-nederland.nl/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "internal_urls = set()\n",
    "external_urls = set()\n",
    "\n",
    "def is_valid(url):\n",
    "    parsed = urlparse(url)\n",
    "    return bool(parsed.netloc) and bool(parsed.scheme)\n",
    "\n",
    "def get_all_website_links(url):\n",
    "    urls = set()\n",
    "    domain_name = urlparse(url).netloc\n",
    "    soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "    \n",
    "    for a_tag in soup.findAll(\"a\"):\n",
    "        href = a_tag.attrs.get(\"href\")\n",
    "        if href == \"\" or href is None:\n",
    "            # href empty tag\n",
    "            continue\n",
    "        # join the URL if it's relative (not absolute link)\n",
    "        href = urljoin(url, href)\n",
    "        parsed_href = urlparse(href)\n",
    "        # remove URL GET parameters, URL fragments, etc.\n",
    "        href = parsed_href.scheme + \"://\" + parsed_href.netloc + parsed_href.path\n",
    "        if not is_valid(href):\n",
    "            # not a valid URL\n",
    "            continue\n",
    "        if href in internal_urls:\n",
    "            # already in the set\n",
    "            continue\n",
    "        if domain_name not in href:\n",
    "            # external link\n",
    "            if href not in external_urls:\n",
    "                print(f\"[!] External link: {href}\")\n",
    "                external_urls.add(href)\n",
    "            continue\n",
    "        print(f\"[*] Internal link: {href}\")\n",
    "        urls.add(href)\n",
    "        internal_urls.add(href)\n",
    "        \n",
    "    print(\"[+] Total Internal links:\", len(internal_urls))\n",
    "    print(\"[+] Total External links:\", len(external_urls))\n",
    "        \n",
    "#     return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_valid('https://bouwmaterialen.com/klussen/tuinmuur-maken/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_all_website_links('https://www.bouwmaat.nl/bouwmaterialen')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unnecessary code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from bs4 import BeautifulSoup\n",
    "# import requests\n",
    "# import re\n",
    "\n",
    "# dikz = 0\n",
    "  \n",
    "# # function to extract html document from given url\n",
    "# def getHTMLdocument(url):\n",
    "      \n",
    "#     # request for HTML document of given url\n",
    "#     response = requests.get(url)\n",
    "      \n",
    "#     # response will be provided in JSON format\n",
    "#     return response.text\n",
    "  \n",
    "    \n",
    "# # assign required credentials\n",
    "# # assign URL\n",
    "# url_to_scrape = \"https://www.bouwmaterialenkopen.com/\"\n",
    "  \n",
    "# # create document\n",
    "# html_document = getHTMLdocument(url_to_scrape)\n",
    "  \n",
    "# # create soap object\n",
    "# soup = BeautifulSoup(html_document, 'html.parser')\n",
    "  \n",
    "  \n",
    "# # find all the anchor tags with \"href\" \n",
    "# # attribute starting with \"https://\"\n",
    "# for link in soup.find_all('a', attrs={'href': re.compile(\"^https://\")}):\n",
    "#     # display the actual urls\n",
    "#     print(link.get('href'))\n",
    "#     dikz = dikz + 1\n",
    "#     print(dikz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "try:\n",
    "    code = urlopen(\"https://www.thuiswinkel.org/leden/bouwmaterialenkopen.com/certificaat\").code\n",
    "    print('omega=toaster')\n",
    "except: \n",
    "    print('toaster')\n",
    "    \n",
    "lol = \"https://www.bouwmaterialenkopen.com\"   \n",
    "domain = urlparse(lol).netloc\n",
    "print(domain) # --> www.example.test\n",
    "domain = \"https://\" + domain\n",
    "print(domain)\n",
    "\n",
    "try:\n",
    "    code = urlopen(\"https://www.bouwmaterialenkopen.com/klussen/zwembad-bouwen/\").code\n",
    "    print('omega=toaster')\n",
    "except: \n",
    "    print('toaster')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = \"https://www.bouwmaterialenkopen.com/klussen/zwembad-bouwen/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    code = urlopen(ab).code\n",
    "    print(ab)\n",
    "except:\n",
    "    print('failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lollolol(siteUrll):            \n",
    "    if(siteUrll.startswith('http')):\n",
    "        print(siteUrll + \"w\")\n",
    "    elif(siteUrll.startswith('/')): \n",
    "        domain = urlparse(siteUrll).netloc\n",
    "        domain = \"https://\" + domain\n",
    "                \n",
    "        try:\n",
    "            code = urlopen(\"https://bouwmaterialenkopen.com/\" + siteUrll).code\n",
    "            print(domain + siteUrll + \"WWWWWWWWWWWWWWWWWWWW\")\n",
    "        except:\n",
    "            print(siteUrll + \"Cant OPEN!\")\n",
    "    else:\n",
    "        print(siteUrll + \"i dont start good\")\n",
    "                \n",
    "lollolol('http://www.bouwmaterialen-nederland.nl/keralit-online#255')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
