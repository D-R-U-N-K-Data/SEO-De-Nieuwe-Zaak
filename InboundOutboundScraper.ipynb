{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from urllib.parse import urlparse, urljoin\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from func_timeout import func_timeout, FunctionTimedOut, func_set_timeout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "internal_urls = set()\n",
    "external_urls = set()\n",
    "\n",
    "def is_valid(url):\n",
    "    parsed = urlparse(url)\n",
    "    \n",
    "    if parsed.scheme.startswith('http') and bool(parsed.netloc):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "@func_set_timeout(10)\n",
    "def get_all_website_links(url):\n",
    "    urls = set()\n",
    "    domain_name = urlparse(url).netloc\n",
    "    soup = BeautifulSoup(requests.get(url).content, \"html.parser\")\n",
    "    \n",
    "    total_internal = 0\n",
    "    total_external = 0\n",
    "        \n",
    "    for a_tag in soup.findAll(\"a\"):\n",
    "        \n",
    "        href = a_tag.attrs.get(\"href\")\n",
    "        \n",
    "        if href == \"\" or href is None:\n",
    "            # href empty tag\n",
    "            continue\n",
    "        href = urljoin(url, href)\n",
    "        parsed_href = urlparse(href)\n",
    "        href = parsed_href.scheme + \"://\" + parsed_href.netloc + parsed_href.path\n",
    "        if not is_valid(href):\n",
    "            # not a valid URL\n",
    "            continue\n",
    "            \n",
    "        if href in internal_urls:\n",
    "            total_internal = total_internal + 1\n",
    "            continue\n",
    "            \n",
    "        if domain_name not in href:\n",
    "            total_external = total_external + 1\n",
    "            if href not in external_urls:\n",
    "                external_urls.add(href)\n",
    "            continue\n",
    "            \n",
    "        urls.add(href)\n",
    "        internal_urls.add(href)\n",
    "        total_internal = total_internal + 1\n",
    "                \n",
    "    return total_internal, total_external"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.DataFrame({\n",
    "#     'Url':['https://www.bouwmaat.nl/bouwmaterialen','https://www.hornbach.nl/shop/Bouwmateriaal/S4471/artikeloverzicht.html','https://www.bouwbestel.nl/bouwmaterialen.html'],\n",
    "#     'Internal':[0,0,0],\n",
    "#     'External':[0,0,0]\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_get_all_website_links(dataframe):\n",
    "    InternalLinks = []\n",
    "    ExternalLinks = []\n",
    "    for url in dataframe.index:\n",
    "        try:\n",
    "            var = get_all_website_links(dataframe['Ur'][url])\n",
    "        except:\n",
    "            var = [None, None]\n",
    "        InternalLinks.append(var[0])\n",
    "        ExternalLinks.append(var[1])\n",
    "    return InternalLinks, ExternalLinks\n",
    "\n",
    "# counter = 0\n",
    "# for i in df.Url:\n",
    "#     gadget = get_all_website_links(i)\n",
    "#     df.Internal[counter] = gadget[0]\n",
    "#     df.External[counter] = gadget[1]\n",
    "#     counter = counter + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([1425, 217, 2595, 138, 563, 1029, 0, 615, 138, 348, 440, 349, 297, 24, 87, 784, 70, 158, 299, 162, 117, 64, 828, 518, 598, 34, 109, 62, 50, 197, 134, 59, 371, 276, 400, 28, None, 229, 0, 61, 371, 109, 487, 85, 99, 128, 197, 24, 1504, 713], [11, 7, 14, 10, 5, 3, 0, 5, 9, 16, 5, 3, 13, 6, 10, 16, 10, 6, 13, 70, 0, 1, 16, 14, 11, 4, 1, 3, 10, 7, 52, 6, 6, 45, 10, 3, None, 3, 0, 14, 9, 10, 6, 9, 18, 14, 7, 2, 7, 3])\n"
     ]
    }
   ],
   "source": [
    "# dataframe = pd.read_csv(\"calls\\dataframe-73f2a3dfe1f688c31ab0ae26a247078465169f60f9a383c28fc900bc7d01a132.csv\")\n",
    "\n",
    "print(loop_get_all_website_links(dataframe))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
